---
title: "Filter Movies 2012-2023"
author: "Sofia Villamil"
date: "2024-05-31"
output: html_document
---

### Data Base

We are going to use as a base, a data set from Kaggel called "**Full TMDB Movies Dataset 2024 (1M Movies)"** (Link to the data: <https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies>). This data will be filtered for the year 2012-2023 and will be complemented with scrapping of different websites to get other variables.

```{r}
rm(list = ls())
```

```{r}
library(readr)
library(dplyr)

movies <- read_delim("C:/Users/sofia/Documents/Documentos/Master Computational Social Sciences/TFM/Master Thesis/Scrapping Part 1/TMDB_movie_dataset_v11_1mill.csv", 
    delim = ";", escape_double = FALSE, trim_ws = TRUE,show_col_types = FALSE)

# Some columns with NA's where generated
movies_cleaned <- movies %>%
  select(where(~ !all(is.na(.))))

# filtering for the years I want in the data set
filtered_movies <- movies_cleaned %>%
  filter(year > 2011 & year < 2024)

# Save the filtered dataset to a CSV file
write.csv(filtered_movies, "C:/Users/sofia/Documents/Documentos/Master Computational Social Sciences/TFM/Master Thesis/Scrapping Part 1/TMDB_movie_dataset_v11_1mill_filter.csv", row.names = FALSE)

```

Checking that I can scrap the data from this pages. Meaning I have permit to access and index every part of the site without any restrictions.

```{r}
library(robotstxt)
paths_allowed("https://www.imdb.com/")
paths_allowed("https://www.boxofficemojo.com/")
paths_allowed("https://www.rottentomatoes.com/")
paths_allowed("https://www.the-numbers.com/")
paths_allowed("https://www.google.com/")
paths_allowed("https://www.youtube.com/")
paths_allowed("https://www.themoviedb.org/")
```

We will now start scrapping the first page in the next script called "Scrapping final data Script_Part_2"
